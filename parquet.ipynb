{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff42e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "parquet_path = \"data/raw/ride_data_parquet/*.parquet\"\n",
    "jan_parquet = \"data/raw/ride_data_parquet/fhvhv_tripdata_2024-01.parquet\"\n",
    "taxi_zone = \"data/processed/taxi_zones.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c4fbf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OBJECTID  Shape_Leng  Shape_Area                       zone  LocationID  \\\n",
      "0          1    0.116357    0.000782             Newark Airport           1   \n",
      "1          2    0.433470    0.004866                Jamaica Bay           2   \n",
      "2          3    0.084341    0.000314    Allerton/Pelham Gardens           3   \n",
      "3          4    0.043567    0.000112              Alphabet City           4   \n",
      "4          5    0.092146    0.000498              Arden Heights           5   \n",
      "..       ...         ...         ...                        ...         ...   \n",
      "95        96    0.185180    0.000548  Forest Park/Highland Park          96   \n",
      "96        97    0.062476    0.000163                Fort Greene          97   \n",
      "97        98    0.121661    0.000486              Fresh Meadows          98   \n",
      "98        99    0.183371    0.001210            Freshkills Park          99   \n",
      "99       100    0.024813    0.000037           Garment District         100   \n",
      "\n",
      "          borough                                           geometry  \\\n",
      "0             EWR  [1, 3, 0, 0, 0, 1, 0, 0, 0, 232, 0, 0, 0, 146,...   \n",
      "1          Queens  [1, 6, 0, 0, 0, 33, 0, 0, 0, 1, 3, 0, 0, 0, 1,...   \n",
      "2           Bronx  [1, 3, 0, 0, 0, 1, 0, 0, 0, 121, 0, 0, 0, 0, 1...   \n",
      "3       Manhattan  [1, 3, 0, 0, 0, 1, 0, 0, 0, 88, 0, 0, 0, 128, ...   \n",
      "4   Staten Island  [1, 3, 0, 0, 0, 1, 0, 0, 0, 170, 0, 0, 0, 0, 2...   \n",
      "..            ...                                                ...   \n",
      "95         Queens  [1, 3, 0, 0, 0, 1, 0, 0, 0, 14, 1, 0, 0, 0, 15...   \n",
      "96       Brooklyn  [1, 3, 0, 0, 0, 1, 0, 0, 0, 112, 0, 0, 0, 128,...   \n",
      "97         Queens  [1, 3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 156...   \n",
      "98  Staten Island  [1, 3, 0, 0, 0, 1, 0, 0, 0, 78, 4, 0, 0, 128, ...   \n",
      "99      Manhattan  [1, 3, 0, 0, 0, 1, 0, 0, 0, 25, 0, 0, 0, 128, ...   \n",
      "\n",
      "                                             centroid   centroid_lat  \\\n",
      "0   [1, 1, 0, 0, 0, 121, 60, 92, 164, 121, 144, 44...  191376.749531   \n",
      "1   [1, 1, 0, 0, 0, 10, 197, 236, 111, 91, 119, 47...  164018.754403   \n",
      "2   [1, 1, 0, 0, 0, 254, 214, 214, 59, 41, 83, 47,...  254265.478659   \n",
      "3   [1, 1, 0, 0, 0, 92, 149, 22, 246, 83, 59, 46, ...  202959.782391   \n",
      "4   [1, 1, 0, 0, 0, 2, 142, 121, 189, 62, 112, 44,...  140681.351376   \n",
      "..                                                ...            ...   \n",
      "95  [1, 1, 0, 0, 0, 126, 137, 159, 92, 178, 31, 47...  193239.009530   \n",
      "96  [1, 1, 0, 0, 0, 250, 68, 128, 101, 223, 63, 46...  190949.618064   \n",
      "97  [1, 1, 0, 0, 0, 123, 145, 98, 183, 186, 235, 4...  206939.617855   \n",
      "98  [1, 1, 0, 0, 0, 183, 231, 116, 39, 223, 116, 4...  149465.339575   \n",
      "99  [1, 1, 0, 0, 0, 86, 160, 89, 134, 185, 33, 46,...  213801.890336   \n",
      "\n",
      "    centroid_lon nearest_node_id  \n",
      "0   9.359968e+05        42850178  \n",
      "1   1.031086e+06        42850178  \n",
      "2   1.026453e+06        42850178  \n",
      "3   9.906340e+05        42850178  \n",
      "4   9.318714e+05        42850178  \n",
      "..           ...             ...  \n",
      "95  1.019865e+06        42850178  \n",
      "96  9.912157e+05        42850178  \n",
      "97  1.045981e+06        42850178  \n",
      "98  9.324636e+05        42850178  \n",
      "99  9.873568e+05        42850178  \n",
      "\n",
      "[100 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "query = f\"SELECT * FROM '{taxi_zone}'\"\n",
    "df = duckdb.query(query).to_df()\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c923df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             column_name column_type null   key default extra\n",
      "0      hvfhs_license_num     VARCHAR  YES  None    None  None\n",
      "1   dispatching_base_num     VARCHAR  YES  None    None  None\n",
      "2   originating_base_num     VARCHAR  YES  None    None  None\n",
      "3       request_datetime   TIMESTAMP  YES  None    None  None\n",
      "4      on_scene_datetime   TIMESTAMP  YES  None    None  None\n",
      "5        pickup_datetime   TIMESTAMP  YES  None    None  None\n",
      "6       dropoff_datetime   TIMESTAMP  YES  None    None  None\n",
      "7           PULocationID     INTEGER  YES  None    None  None\n",
      "8           DOLocationID     INTEGER  YES  None    None  None\n",
      "9             trip_miles      DOUBLE  YES  None    None  None\n",
      "10             trip_time      BIGINT  YES  None    None  None\n",
      "11   base_passenger_fare      DOUBLE  YES  None    None  None\n",
      "12                 tolls      DOUBLE  YES  None    None  None\n",
      "13                   bcf      DOUBLE  YES  None    None  None\n",
      "14             sales_tax      DOUBLE  YES  None    None  None\n",
      "15  congestion_surcharge      DOUBLE  YES  None    None  None\n",
      "16           airport_fee      DOUBLE  YES  None    None  None\n",
      "17                  tips      DOUBLE  YES  None    None  None\n",
      "18            driver_pay      DOUBLE  YES  None    None  None\n",
      "19   shared_request_flag     VARCHAR  YES  None    None  None\n",
      "20     shared_match_flag     VARCHAR  YES  None    None  None\n",
      "21    access_a_ride_flag     VARCHAR  YES  None    None  None\n",
      "22      wav_request_flag     VARCHAR  YES  None    None  None\n",
      "23        wav_match_flag     VARCHAR  YES  None    None  None\n"
     ]
    }
   ],
   "source": [
    "query = f\"DESCRIBE '{jan_parquet}'\"\n",
    "df = duckdb.query(query).to_df()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa599325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned data and saved to 'data/processed/cleaned_ride_data.parquet'\n"
     ]
    }
   ],
   "source": [
    "# Drop the existing table before creating a new one\n",
    "duckdb.query(\"DROP TABLE IF EXISTS cleaned_ride_data\")\n",
    "\n",
    "# Create the cleaned table\n",
    "query = f\"\"\"\n",
    "CREATE TABLE cleaned_ride_data AS \n",
    "SELECT request_datetime, pickup_datetime, dropoff_datetime, PULocationID, \n",
    "DOLocationID, trip_miles, trip_time, base_passenger_fare, \n",
    "congestion_surcharge, driver_pay\n",
    "FROM '{jan_parquet}';\n",
    "\"\"\"\n",
    "duckdb.query(query)\n",
    "\n",
    "# Save cleaned data as a new Parquet file\n",
    "duckdb.query(\"COPY cleaned_ride_data TO 'data/processed/cleaned_ride_data.parquet' (FORMAT PARQUET)\")\n",
    "\n",
    "print(\"Successfully cleaned data and saved to 'data/processed/cleaned_ride_data.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcbc7490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     request_datetime     pickup_datetime    dropoff_datetime  PULocationID  \\\n",
      "0 2024-01-01 00:03:47 2024-01-01 00:06:15 2024-01-01 00:27:53           255   \n",
      "1 2024-01-01 00:22:51 2024-01-01 00:29:47 2024-01-01 00:50:08            95   \n",
      "2 2024-01-01 00:29:43 2024-01-01 00:37:50 2024-01-01 00:58:44           195   \n",
      "3 2024-01-01 00:08:37 2024-01-01 00:11:17 2024-01-01 00:27:44           229   \n",
      "4 2024-01-01 00:42:04 2024-01-01 00:53:16 2024-01-01 01:41:05           249   \n",
      "\n",
      "   DOLocationID  trip_miles  trip_time  base_passenger_fare  \\\n",
      "0            95       7.020       1298                32.16   \n",
      "1           212      11.330       1221                45.83   \n",
      "2           112       7.370       1254                37.68   \n",
      "3            87       5.477        987                22.78   \n",
      "4           188       7.643       2869                35.10   \n",
      "\n",
      "   congestion_surcharge  driver_pay  \n",
      "0                  0.00       24.35  \n",
      "1                  0.00       30.98  \n",
      "2                  0.00       50.54  \n",
      "3                  2.75       19.10  \n",
      "4                  2.75       41.34  \n"
     ]
    }
   ],
   "source": [
    "test_parquet = \"data/processed/cleaned_ride_data.parquet\"\n",
    "query = f\"SELECT * FROM '{test_parquet}' WHERE trip_miles > 5\"\n",
    "df = duckdb.query(query).to_df()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96500b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FuQuan\\AppData\\Local\\Temp\\ipykernel_17748\\3253363326.py:51: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones[\"pickup_lat\"] = taxi_zones.geometry.centroid.y\n",
      "C:\\Users\\FuQuan\\AppData\\Local\\Temp\\ipykernel_17748\\3253363326.py:52: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones[\"pickup_lon\"] = taxi_zones.geometry.centroid.x\n",
      "C:\\Users\\FuQuan\\AppData\\Local\\Temp\\ipykernel_17748\\3253363326.py:53: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones[\"dropoff_lat\"] = taxi_zones.geometry.centroid.y\n",
      "C:\\Users\\FuQuan\\AppData\\Local\\Temp\\ipykernel_17748\\3253363326.py:54: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones[\"dropoff_lon\"] = taxi_zones.geometry.centroid.x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully processed ride data with lat/lon mapping. Data saved to data/processed/ride_data/enriched_ride_data.parquet\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import duckdb\n",
    "\n",
    "duckdb.query(\"DROP TABLE IF EXISTS enriched_ride_data\")\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE enriched_ride_data (\n",
    "    request_datetime TIMESTAMP,\n",
    "    pickup_datetime TIMESTAMP,\n",
    "    dropoff_datetime TIMESTAMP,\n",
    "    PULocationID INT,\n",
    "    DOLocationID INT,\n",
    "    trip_miles DOUBLE,\n",
    "    trip_time DOUBLE,\n",
    "    base_passenger_fare DOUBLE,\n",
    "    congestion_surcharge DOUBLE,\n",
    "    driver_pay DOUBLE,\n",
    "    pickup_lat DOUBLE,\n",
    "    pickup_lon DOUBLE,\n",
    "    dropoff_lat DOUBLE,\n",
    "    dropoff_lon DOUBLE,\n",
    "    trip_duration DOUBLE,  -- dropoff_datetime - pickup_datetime in seconds\n",
    "    wait_time DOUBLE,  -- pickup_datetime - request_datetime in seconds\n",
    "    avg_speed DOUBLE,  -- miles per hour\n",
    ");\n",
    "\"\"\"\n",
    "duckdb.query(create_table_query)\n",
    "\n",
    "# Define file paths\n",
    "ride_data_parquet = \"data/processed/ride_data/cleaned_ride_data.parquet\"\n",
    "shapefile_path = \"data/raw/taxi_zones/taxi_zones.shp\"\n",
    "output_parquet = \"data/processed/ride_data/enriched_ride_data.parquet\"\n",
    "\n",
    "# Step 1: Load Taxi Zones Shapefile\n",
    "taxi_zones = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Step 2: Convert CRS (Projected to WGS84)\n",
    "if taxi_zones.crs != \"EPSG:4326\":\n",
    "    taxi_zones = taxi_zones.to_crs(epsg=2263)  # Convert to projected CRS first\n",
    "\n",
    "# Step 3: Compute Centroids in EPSG:2263 for accurate location mapping\n",
    "taxi_zones[\"pickup_lat\"] = taxi_zones.geometry.centroid.y\n",
    "taxi_zones[\"pickup_lon\"] = taxi_zones.geometry.centroid.x\n",
    "taxi_zones[\"dropoff_lat\"] = taxi_zones.geometry.centroid.y\n",
    "taxi_zones[\"dropoff_lon\"] = taxi_zones.geometry.centroid.x\n",
    "\n",
    "# Step 4: Convert back to WGS84 (EPSG:4326) for final latitude/longitude\n",
    "taxi_zones = taxi_zones.to_crs(epsg=4326)\n",
    "\n",
    "# Extract final geospatial coordinates\n",
    "taxi_zones[\"pickup_lat\"] = taxi_zones.geometry.centroid.y\n",
    "taxi_zones[\"pickup_lon\"] = taxi_zones.geometry.centroid.x\n",
    "taxi_zones[\"dropoff_lat\"] = taxi_zones.geometry.centroid.y\n",
    "taxi_zones[\"dropoff_lon\"] = taxi_zones.geometry.centroid.x\n",
    "\n",
    "# Remove geometry column before DuckDB processing\n",
    "taxi_zones = taxi_zones.drop(columns=[\"geometry\"])  \n",
    "\n",
    "# Step 5: Store Taxi Zones in DuckDB\n",
    "conn = duckdb.connect(database=':memory:', read_only=False)\n",
    "conn.register('taxi_zones', taxi_zones)\n",
    "\n",
    "# Step 6: Load Ride Data\n",
    "duckdb.query(f\"CREATE OR REPLACE TABLE ride_data AS SELECT * FROM '{ride_data_parquet}'\")\n",
    "\n",
    "# Step 7: Process Data Efficiently in Batches\n",
    "query = f\"\"\"\n",
    "INSERT INTO enriched_ride_data\n",
    "SELECT ride.*, \n",
    "    tz_pickup.pickup_lat, tz_pickup.pickup_lon, \n",
    "    tz_dropoff.dropoff_lat, tz_dropoff.dropoff_lon,\n",
    "    date_part('epoch', dropoff_datetime - pickup_datetime) AS trip_duration,\n",
    "    date_part('epoch', pickup_datetime - request_datetime) AS wait_time,\n",
    "    trip_miles / (date_part('epoch', dropoff_datetime - pickup_datetime) / 3600) AS avg_speed,\n",
    "FROM cleaned_ride_data AS ride\n",
    "LEFT JOIN taxi_zones AS tz_pickup ON ride.PULocationID = tz_pickup.LocationID\n",
    "LEFT JOIN taxi_zones AS tz_dropoff ON ride.DOLocationID = tz_dropoff.LocationID\n",
    "WHERE tz_pickup.pickup_lat IS NOT NULL \n",
    "AND tz_dropoff.dropoff_lat IS NOT NULL \n",
    "AND date_part('epoch', dropoff_datetime - pickup_datetime) > 0\n",
    "\"\"\"\n",
    "\n",
    "duckdb.query(query)\n",
    "\n",
    "# Step 8: Save Processed Data in Parquet Format\n",
    "duckdb.query(f\"COPY enriched_ride_data TO '{output_parquet}' (FORMAT 'parquet')\")\n",
    "\n",
    "print(f\"✅ Successfully processed ride data with lat/lon mapping. Data saved to {output_parquet}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ffc175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     request_datetime     pickup_datetime    dropoff_datetime  PULocationID  \\\n",
      "0 2024-01-01 00:03:47 2024-01-01 00:06:15 2024-01-01 00:27:53           255   \n",
      "1 2024-01-01 00:03:47 2024-01-01 00:05:36 2024-01-01 00:08:30           174   \n",
      "2 2024-01-01 00:03:47 2024-01-01 00:06:18 2024-01-01 00:21:04            80   \n",
      "3 2024-01-01 00:03:47 2024-01-01 00:08:51 2024-01-01 00:23:25           122   \n",
      "4 2024-01-01 00:03:47 2024-01-01 00:06:39 2024-01-01 00:22:40            25   \n",
      "\n",
      "   DOLocationID  trip_miles  trip_time  base_passenger_fare  \\\n",
      "0            95       7.020     1298.0                32.16   \n",
      "1           240       0.472      174.0                 8.05   \n",
      "2           170       5.590      886.0                22.79   \n",
      "3            38       3.020      874.0                15.15   \n",
      "4           227       4.859      961.0                19.62   \n",
      "\n",
      "   congestion_surcharge  driver_pay  pickup_lat  pickup_lon  dropoff_lat  \\\n",
      "0                  0.00       24.35   40.718804  -73.957418    40.721432   \n",
      "1                  0.00        5.47   40.877138  -73.879022    40.894599   \n",
      "2                  2.75       16.22   40.715370  -73.936793    40.747746   \n",
      "3                  0.00       12.19   40.710639  -73.761137    40.694341   \n",
      "4                  0.00       19.54   40.685634  -73.986114    40.641886   \n",
      "\n",
      "   dropoff_lon  trip_duration  wait_time  avg_speed  \n",
      "0   -73.847669         1298.0      148.0  19.469954  \n",
      "1   -73.881978          174.0      109.0   9.765517  \n",
      "2   -73.978492          886.0      151.0  22.713318  \n",
      "3   -73.735554          874.0      304.0  12.439359  \n",
      "4   -74.004652          961.0      172.0  18.202289  \n"
     ]
    }
   ],
   "source": [
    "test_parquet = \"data/processed/ride_data/enriched_ride_data.parquet\"\n",
    "query = f\"SELECT * FROM '{test_parquet}' WHERE request_datetime = '2024-01-01 00:03:47'\"\n",
    "df = duckdb.query(query).to_df()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431957a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pickup_lat  pickup_lon  dropoff_lat  dropoff_lon\n",
      "0   40.691831  -74.174000    40.691831   -74.174000\n",
      "1   40.616745  -73.831299    40.616745   -73.831299\n",
      "2   40.864474  -73.847422    40.864474   -73.847422\n",
      "3   40.723752  -73.976968    40.723752   -73.976968\n",
      "4   40.552659  -74.188484    40.552659   -74.188484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FuQuan\\AppData\\Local\\Temp\\ipykernel_17748\\489494876.py:19: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones[\"pickup_lat\"] = taxi_zones.geometry.centroid.y\n",
      "C:\\Users\\FuQuan\\AppData\\Local\\Temp\\ipykernel_17748\\489494876.py:20: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones[\"pickup_lon\"] = taxi_zones.geometry.centroid.x\n",
      "C:\\Users\\FuQuan\\AppData\\Local\\Temp\\ipykernel_17748\\489494876.py:21: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones[\"dropoff_lat\"] = taxi_zones.geometry.centroid.y\n",
      "C:\\Users\\FuQuan\\AppData\\Local\\Temp\\ipykernel_17748\\489494876.py:22: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones[\"dropoff_lon\"] = taxi_zones.geometry.centroid.x\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load Taxi Zones shapefile\n",
    "taxi_zones = gpd.read_file(\"data/raw/taxi_zones/taxi_zones.shp\")\n",
    "\n",
    "# Convert from EPSG:4326 (geographic CRS) to EPSG:2263 (projected CRS)\n",
    "taxi_zones = taxi_zones.to_crs(epsg=2263)\n",
    "\n",
    "# Compute centroids (correctly using projected coordinates)\n",
    "taxi_zones[\"pickup_lat_proj\"] = taxi_zones.geometry.centroid.y\n",
    "taxi_zones[\"pickup_lon_proj\"] = taxi_zones.geometry.centroid.x\n",
    "taxi_zones[\"dropoff_lat_proj\"] = taxi_zones.geometry.centroid.y\n",
    "taxi_zones[\"dropoff_lon_proj\"] = taxi_zones.geometry.centroid.x\n",
    "\n",
    "# Convert back to EPSG:4326 for correct latitude & longitude\n",
    "taxi_zones = taxi_zones.to_crs(epsg=4326)\n",
    "\n",
    "# Extract final lat/lon values\n",
    "taxi_zones[\"pickup_lat\"] = taxi_zones.geometry.centroid.y\n",
    "taxi_zones[\"pickup_lon\"] = taxi_zones.geometry.centroid.x\n",
    "taxi_zones[\"dropoff_lat\"] = taxi_zones.geometry.centroid.y\n",
    "taxi_zones[\"dropoff_lon\"] = taxi_zones.geometry.centroid.x\n",
    "\n",
    "# Validate the output\n",
    "print(taxi_zones[[\"pickup_lat\", \"pickup_lon\", \"dropoff_lat\", \"dropoff_lon\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9feab9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Loaded: 55242 nodes, 139297 edges\n",
      "Sample Maxspeed Values: ['50 mph', 'Unknown', 'Unknown', '50 mph', 'Unknown', '50 mph', '25 mph', 'Unknown', '25 mph', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', '25 mph', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', '25 mph', 'Unknown', 'Unknown', '25 mph', 'Unknown', 'Unknown', '25 mph', 'Unknown', 'Unknown', 'Unknown', '25 mph', 'Unknown', '25 mph', '25 mph', 'Unknown', 'Unknown', 'Unknown', 'Unknown', '20 mph', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', '25 mph', '25 mph', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', '25 mph', 'Unknown', '25 mph', '25 mph', 'Unknown', 'Unknown', 'Unknown', '20 mph', '20 mph', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', '25 mph', '25 mph', '25 mph', '25 mph', '20 mph', '20 mph', '20 mph', '20 mph', '20 mph', '20 mph', '20 mph', '20 mph', '20 mph', '20 mph', '20 mph', '25 mph', 'Unknown', '25 mph', 'Unknown', '25 mph', '25 mph', '25 mph', 'Unknown', '25 mph', 'Unknown', 'Unknown', 'Unknown', '25 mph']\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Load the road network from a GraphML file\n",
    "G = nx.read_graphml(\"data/processed/road_graph/new_york_processed_network.graphml\")\n",
    "\n",
    "# Print basic information about the graph\n",
    "print(f\"Graph Loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# Extract and display sample maxspeed values from edges\n",
    "sample_maxspeeds = []\n",
    "\n",
    "for u, v, data in list(G.edges(data=True))[:100]:  # Limit to first 100 edges\n",
    "    sample_maxspeeds.append(data.get('maxspeed', 'Unknown'))  # Retrieve maxspeed or default to 'Unknown'\n",
    "\n",
    "print(\"Sample Maxspeed Values:\", sample_maxspeeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b97f928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Nodes: [('39076461', {'y': '40.7863451', 'x': '-73.7947484', 'highway': 'motorway_junction', 'ref': '33', 'street_count': '3'}), ('39076490', {'y': '40.7624294', 'x': '-73.7570906', 'highway': 'motorway_junction', 'ref': '31W', 'street_count': '3'}), ('39076504', {'y': '40.7534671', 'x': '-73.7441643', 'highway': 'motorway_junction', 'ref': '30W', 'street_count': '3'}), ('42421728', {'y': '40.7980478', 'x': '-73.9600437', 'highway': 'traffic_signals', 'street_count': '3'}), ('42421731', {'y': '40.7986542', 'x': '-73.9614745', 'highway': 'traffic_signals', 'street_count': '4'})]\n",
      "Sample Nodes: [('39076461', '274283981', {'osmid': '25161349', 'highway': 'motorway', 'lanes': '2', 'maxspeed': '50 mph', 'name': 'Cross Island Parkway', 'oneway': 'True', 'ref': 'CI', 'reversed': 'False', 'length': '819.5016661477803', 'geometry': 'LINESTRING (-73.7947484 40.7863451, -73.794615 40.7863898, -73.7944856 40.7864343, -73.7943563 40.7864809, -73.7942289 40.7865266, -73.7940993 40.7865739, -73.7939726 40.7866211, -73.7938448 40.786671, -73.7937196 40.7867213, -73.793594 40.7867723, -73.793465 40.7868253, -73.7933444 40.7868769, -73.7932188 40.7869306, -73.7930954 40.786984, -73.7929753 40.7870377, -73.7928501 40.7870933, -73.7927279 40.7871496, -73.7926059 40.7872061, -73.7909163 40.7880014, -73.790792 40.7880566, -73.7906687 40.7881112, -73.7905452 40.788166, -73.7904232 40.7882185, -73.7903022 40.7882687, -73.7901731 40.788322, -73.7900483 40.7883727, -73.7899209 40.7884227, -73.7897938 40.7884715, -73.7896694 40.7885183, -73.7895408 40.7885667, -73.7894104 40.7886139, -73.7892832 40.7886587, -73.7891563 40.7887019, -73.7890238 40.7887451, -73.7888912 40.788787, -73.7887632 40.7888264, -73.7886299 40.7888655, -73.7884982 40.788904, -73.7883607 40.7889423, -73.7882291 40.7889779, -73.7880942 40.7890128, -73.7879575 40.7890464, -73.7878231 40.7890787, -73.7876873 40.7891097, -73.7875503 40.7891395, -73.7874134 40.7891683, -73.7872765 40.789195, -73.78714 40.7892213, -73.7870025 40.7892452, -73.7868924 40.7892625, -73.7867858 40.7892791, -73.7866664 40.7892952, -73.7865266 40.7893131, -73.7863885 40.7893301, -73.7862474 40.7893469, -73.7861069 40.7893617, -73.7859633 40.7893759)'}), ('39076461', '42854803', {'osmid': '25161578', 'highway': 'motorway_link', 'oneway': 'True', 'reversed': 'False', 'length': '268.1440952459794', 'geometry': 'LINESTRING (-73.7947484 40.7863451, -73.7933159 40.7867884, -73.7931917 40.7868285, -73.7930816 40.7868672, -73.792978 40.7869061, -73.7928878 40.7869409, -73.7928086 40.7869726, -73.7927378 40.7870027, -73.7926698 40.7870305, -73.7921607 40.7872621, -73.7921252 40.7872747, -73.7920916 40.7872822, -73.7920535 40.7872824, -73.7920208 40.7872736, -73.791997 40.7872539, -73.7919229 40.7871641)'}), ('39076490', '277672046', {'osmid': '5699971', 'highway': 'motorway_link', 'oneway': 'True', 'reversed': 'False', 'length': '259.9234870362934', 'geometry': 'LINESTRING (-73.7570906 40.7624294, -73.7572099 40.7626147, -73.7573357 40.7628243, -73.7573687 40.7628831, -73.7573935 40.7629657, -73.7574017 40.7630182, -73.7573869 40.7630758, -73.7573736 40.7631171, -73.757329 40.7631696, -73.7572729 40.7632021, -73.7572052 40.7632247, -73.7571341 40.7632284, -73.757045 40.7632284, -73.7569657 40.7632196, -73.7568071 40.7631771, -73.7566519 40.7631121, -73.7565478 40.7630545, -73.756457 40.7629895, -73.7563876 40.7629244, -73.7563529 40.7628744, -73.7563314 40.7628293, -73.7563166 40.7627793, -73.7563172 40.7627252, -73.756338 40.7626629, -73.7563562 40.7626179, -73.7564004 40.7625523, -73.7564318 40.7625207, -73.7565432 40.7624458, -73.7567291 40.7623708)'}), ('39076490', '277672005', {'osmid': '1014007069', 'highway': 'motorway', 'lanes': '3', 'maxspeed': '50 mph', 'name': 'Cross Island Parkway', 'oneway': 'True', 'ref': 'CI', 'reversed': 'False', 'length': '291.83869462800163', 'geometry': 'LINESTRING (-73.7570906 40.7624294, -73.7574082 40.7627545, -73.7576829 40.7630665, -73.7579575 40.7634046, -73.7581549 40.7636971, -73.7583352 40.7640221, -73.7584639 40.7643342, -73.758627 40.7647567)'}), ('39076504', '462124701', {'osmid': '[618709517, 618709515, 5700693]', 'highway': 'motorway_link', 'lanes': '1', 'oneway': 'True', 'reversed': 'False', 'length': '433.14985047751736', 'bridge': 'yes', 'geometry': 'LINESTRING (-73.7441643 40.7534671, -73.7445334 40.7540522, -73.7446707 40.7542668, -73.7447137 40.7543483, -73.7447416 40.7544273, -73.7447597 40.7544853, -73.7447803 40.7545729, -73.7447874 40.7546513, -73.7447869 40.7547254, -73.7447777 40.7547993, -73.7447606 40.7548744, -73.7447285 40.7549532, -73.7446922 40.755013, -73.7446443 40.7550707, -73.7446008 40.755115, -73.7445118 40.7551819, -73.7444033 40.755257, -73.7443025 40.7553062, -73.744242 40.7553301, -73.7441696 40.7553481, -73.7439881 40.7553781, -73.7438596 40.7553794, -73.7437187 40.7553666, -73.7436102 40.7553427, -73.7435239 40.7553111, -73.743441 40.7552687, -73.7433807 40.7552259, -73.7433209 40.7551645, -73.7432829 40.7551116, -73.7432572 40.7550385, -73.743246 40.7549763, -73.743246 40.7549048, -73.7432678 40.7548228, -73.7432992 40.7547598, -73.743384 40.7546457, -73.7435061 40.7544937, -73.743724 40.7542921)'})]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Nodes:\", list(G.nodes(data=True))[:5])\n",
    "print(\"Sample Nodes:\", list(G.edges(data=True))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8382b560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: 39076461 | Degree: 3 | Street Count: 3\n",
      "Node: 39076490 | Degree: 3 | Street Count: 3\n",
      "Node: 39076504 | Degree: 3 | Street Count: 3\n",
      "Node: 42421728 | Degree: 6 | Street Count: 3\n",
      "Node: 42421731 | Degree: 8 | Street Count: 4\n",
      "Node: 42421737 | Degree: 6 | Street Count: 4\n",
      "Node: 42421741 | Degree: 6 | Street Count: 4\n",
      "Node: 42421745 | Degree: 6 | Street Count: 4\n",
      "Node: 42421749 | Degree: 7 | Street Count: 4\n",
      "Node: 42421751 | Degree: 4 | Street Count: 3\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "# Validate street_count vs degree\n",
    "validation_results = []\n",
    "\n",
    "for node in G.nodes():\n",
    "    degree = G.degree(node)  # Count edges\n",
    "    street_count = int(G.nodes[node].get('street_count', 0))  # Extract street count\n",
    "    \n",
    "    validation_results.append((node, degree, street_count))\n",
    "\n",
    "# Print the first 10 nodes for comparison\n",
    "for node, degree, street_count in validation_results[:10]:\n",
    "    print(f\"Node: {node} | Degree: {degree} | Street Count: {street_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf046a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
